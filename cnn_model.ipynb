{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54050d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================================\n",
    "# 1. DATA PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "class ProteinDataProcessor:\n",
    "    \"\"\"Handles encoding of amino acid sequences and structure labels\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # 20 standard amino acids\n",
    "        self.amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "        self.aa_to_idx = {aa: idx for idx, aa in enumerate(self.amino_acids)}\n",
    "        \n",
    "        # 3-state secondary structure: H (helix), E (sheet), C (coil)\n",
    "        self.structures = 'HEC'\n",
    "        self.struct_to_idx = {s: idx for idx, s in enumerate(self.structures)}\n",
    "        \n",
    "    def encode_sequence(self, sequence):\n",
    "        \"\"\"One-hot encode amino acid sequence\"\"\"\n",
    "        # Shape: (sequence_length, 20)\n",
    "        encoded = np.zeros((len(sequence), len(self.amino_acids)))\n",
    "        for i, aa in enumerate(sequence):\n",
    "            if aa in self.aa_to_idx:\n",
    "                encoded[i, self.aa_to_idx[aa]] = 1\n",
    "        return encoded\n",
    "    \n",
    "    def encode_structure(self, structure):\n",
    "        \"\"\"One-hot encode secondary structure labels\"\"\"\n",
    "        # Shape: (sequence_length, 3)\n",
    "        encoded = np.zeros((len(structure), len(self.structures)))\n",
    "        for i, s in enumerate(structure):\n",
    "            if s in self.struct_to_idx:\n",
    "                encoded[i, self.struct_to_idx[s]] = 1\n",
    "        return encoded\n",
    "    \n",
    "    def decode_structure(self, encoded):\n",
    "        \"\"\"Convert one-hot encoded structure back to string\"\"\"\n",
    "        indices = np.argmax(encoded, axis=-1)\n",
    "        return ''.join([self.structures[idx] for idx in indices])\n",
    "    \n",
    "    def prepare_dataset(self, sequences, structures, max_length=None):\n",
    "        \"\"\"Prepare padded dataset for training\"\"\"\n",
    "        if max_length is None:\n",
    "            max_length = max(len(seq) for seq in sequences)\n",
    "        \n",
    "        X = np.zeros((len(sequences), max_length, len(self.amino_acids)))\n",
    "        y = np.zeros((len(sequences), max_length, len(self.structures)))\n",
    "        masks = np.zeros((len(sequences), max_length))\n",
    "        \n",
    "        for i, (seq, struct) in enumerate(zip(sequences, structures)):\n",
    "            seq_len = min(len(seq), max_length)\n",
    "            X[i, :seq_len] = self.encode_sequence(seq[:seq_len])\n",
    "            y[i, :seq_len] = self.encode_structure(struct[:seq_len])\n",
    "            masks[i, :seq_len] = 1\n",
    "        \n",
    "        return X, y, masks\n",
    "\n",
    "# ============================================================================\n",
    "# 2. MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "def build_1d_cnn_model(input_shape, num_classes=3):\n",
    "    \"\"\"\n",
    "    Build 1D CNN model for secondary structure prediction\n",
    "    \n",
    "    Architecture:\n",
    "    - Multiple 1D convolutional layers to capture local patterns\n",
    "    - Batch normalization for stable training\n",
    "    - Dropout for regularization\n",
    "    - Final dense layer for classification at each position\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = layers.Conv1D(filters=128, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = layers.Conv1D(filters=128, kernel_size=7, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Third convolutional block (capture longer-range patterns)\n",
    "    x = layers.Conv1D(filters=256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Fourth convolutional block\n",
    "    x = layers.Conv1D(filters=256, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Output layer: predict structure at each position\n",
    "    outputs = layers.Conv1D(filters=num_classes, kernel_size=1, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name='1D_CNN_SecStruct')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ============================================================================\n",
    "# 3. GENERATE SAMPLE DATA (Replace with your real dataset)\n",
    "# ============================================================================\n",
    "\n",
    "def generate_sample_data(n_samples=1000, seq_length=50):\n",
    "    \"\"\"Generate synthetic data for demonstration\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    structures = 'HEC'\n",
    "    \n",
    "    sequences = []\n",
    "    struct_labels = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Random sequence\n",
    "        seq = ''.join(np.random.choice(list(amino_acids), size=seq_length))\n",
    "        \n",
    "        # Simplified structure assignment (not realistic, just for demo)\n",
    "        # In reality, you'd get this from PDB with DSSP annotations\n",
    "        struct = []\n",
    "        for aa in seq:\n",
    "            if aa in 'AVILM':  # Hydrophobic -> more likely helix\n",
    "                struct.append(np.random.choice(['H', 'E', 'C'], p=[0.5, 0.2, 0.3]))\n",
    "            elif aa in 'KRE':  # Charged -> more likely coil\n",
    "                struct.append(np.random.choice(['H', 'E', 'C'], p=[0.2, 0.2, 0.6]))\n",
    "            else:\n",
    "                struct.append(np.random.choice(['H', 'E', 'C'], p=[0.33, 0.33, 0.34]))\n",
    "        \n",
    "        sequences.append(seq)\n",
    "        struct_labels.append(''.join(struct))\n",
    "    \n",
    "    return sequences, struct_labels\n",
    "\n",
    "# ============================================================================\n",
    "# 4. TRAINING PIPELINE\n",
    "# ============================================================================\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"Complete training pipeline\"\"\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"1D CNN SECONDARY STRUCTURE PREDICTION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Generate sample data (replace with real data loading)\n",
    "    print(\"\\n1. Loading data...\")\n",
    "    sequences, structures = generate_sample_data(n_samples=1000, seq_length=50)\n",
    "    print(f\"   Loaded {len(sequences)} sequences\")\n",
    "    print(f\"   Example sequence: {sequences[0][:30]}...\")\n",
    "    print(f\"   Example structure: {structures[0][:30]}...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"\\n2. Preparing dataset...\")\n",
    "    processor = ProteinDataProcessor()\n",
    "    X, y, masks = processor.prepare_dataset(sequences, structures)\n",
    "    print(f\"   X shape: {X.shape}\")\n",
    "    print(f\"   y shape: {y.shape}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test, mask_train, mask_test = train_test_split(\n",
    "        X, y, masks, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(f\"   Training samples: {len(X_train)}\")\n",
    "    print(f\"   Test samples: {len(X_test)}\")\n",
    "    \n",
    "    # Build model\n",
    "    print(\"\\n3. Building model...\")\n",
    "    model = build_1d_cnn_model(input_shape=(X.shape[1], X.shape[2]))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\n4. Training model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    print(\"\\n5. Evaluating model...\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate per-residue accuracy (considering only non-padded positions)\n",
    "    y_true_flat = []\n",
    "    y_pred_flat = []\n",
    "    \n",
    "    for i in range(len(y_test)):\n",
    "        mask = mask_test[i] == 1\n",
    "        y_true_flat.extend(np.argmax(y_test[i][mask], axis=-1))\n",
    "        y_pred_flat.extend(np.argmax(y_pred[i][mask], axis=-1))\n",
    "    \n",
    "    accuracy = accuracy_score(y_true_flat, y_pred_flat)\n",
    "    print(f\"\\n   Overall accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    target_names = ['Helix (H)', 'Sheet (E)', 'Coil (C)']\n",
    "    print(\"\\n   Classification Report:\")\n",
    "    print(classification_report(y_true_flat, y_pred_flat, target_names=target_names))\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    print(\"\\n   Training plots saved to 'training_history.png'\")\n",
    "    \n",
    "    # Example predictions\n",
    "    print(\"\\n6. Example predictions:\")\n",
    "    for i in range(min(3, len(X_test))):\n",
    "        pred = model.predict(X_test[i:i+1], verbose=0)\n",
    "        pred_struct = processor.decode_structure(pred[0])\n",
    "        true_struct = processor.decode_structure(y_test[i])\n",
    "        \n",
    "        # Get original sequence\n",
    "        seq_idx = i\n",
    "        mask = mask_test[i] == 1\n",
    "        seq_decoded = ''.join([processor.amino_acids[np.argmax(X_test[i][j])] \n",
    "                               for j in range(sum(mask))])\n",
    "        \n",
    "        print(f\"\\n   Example {i+1}:\")\n",
    "        print(f\"   Sequence:  {seq_decoded[:40]}...\")\n",
    "        print(f\"   True:      {true_struct[:40]}...\")\n",
    "        print(f\"   Predicted: {pred_struct[:40]}...\")\n",
    "    \n",
    "    return model, processor, history\n",
    "\n",
    "# ============================================================================\n",
    "# 5. RUN TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model, processor, history = train_model()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Training complete!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"- Replace generate_sample_data() with real PDB/DSSP data\")\n",
    "    print(\"- Experiment with different architectures (kernel sizes, filters)\")\n",
    "    print(\"- Try data augmentation or class weighting\")\n",
    "    print(\"- Add bidirectional context with dilated convolutions\")\n",
    "    print(\"- Compare with BiLSTM or Transformer models\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
