{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76887935",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Complete NV Center ODMR Prediction using Graph Neural Networks\n",
    "with Synthetic Data Generation via QuTiP\n",
    "\n",
    "This implementation:\n",
    "1. Generates synthetic ODMR data using QuTiP with time-dependent Hamiltonian\n",
    "2. Creates graph representations of NV center environments\n",
    "3. Trains a GNN to predict ODMR spectra from spin bath configurations\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553b745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from qutip import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff85797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# PART 1: QuTiP-based Synthetic ODMR Data Generation\n",
    "# ============================================================================\n",
    "\n",
    "class NVCenterSimulator:\n",
    "    \"\"\"Simulate NV center ODMR using QuTiP with dissipation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Physical constants (in MHz unless noted)\n",
    "        self.D = 2870.0  # Zero-field splitting (MHz)\n",
    "        self.gamma_e = 28.0  # Electron gyromagnetic ratio (MHz/mT)\n",
    "        self.gamma_n = 0.0031  # 13C nuclear gyromagnetic ratio (MHz/mT)\n",
    "        self.gamma_N = -0.0045  # 14N nuclear gyromagnetic ratio (MHz/mT)\n",
    "        \n",
    "        # Operators for S=1 electron spin\n",
    "        self.Sx = jmat(1, 'x')\n",
    "        self.Sy = jmat(1, 'y')\n",
    "        self.Sz = jmat(1, 'z')\n",
    "        \n",
    "        # Operators for I=1/2 nuclear spins (13C)\n",
    "        self.Ix = 0.5 * sigmax()\n",
    "        self.Iy = 0.5 * sigmay()\n",
    "        self.Iz = 0.5 * sigmaz()\n",
    "        \n",
    "        # Operators for I=1 nitrogen spin (14N)\n",
    "        self.INx = jmat(1, 'x')\n",
    "        self.INy = jmat(1, 'y')\n",
    "        self.INz = jmat(1, 'z')\n",
    "    \n",
    "    def build_hamiltonian(self, B_field, nuclear_config, A_hyperfine, strain=0.0):\n",
    "        \"\"\"\n",
    "        Build NV center Hamiltonian with nuclear spins\n",
    "        \n",
    "        Args:\n",
    "            B_field: Magnetic field in mT (applied along NV axis)\n",
    "            nuclear_config: List of nuclear spin configurations\n",
    "            A_hyperfine: List of hyperfine coupling strengths (MHz)\n",
    "            strain: Strain splitting (MHz)\n",
    "        \"\"\"\n",
    "        # Number of 13C spins\n",
    "        n_nuclear = len(nuclear_config)\n",
    "        \n",
    "        # Electron spin operators in full Hilbert space\n",
    "        # Start with electron spin (3 levels)\n",
    "        dims = [3] + [2] * n_nuclear  # 3 for electron, 2 for each nuclear spin\n",
    "        \n",
    "        # Zero-field splitting term: D * Sz^2\n",
    "        H0 = self.D * self.Sz * self.Sz\n",
    "        \n",
    "        # Add strain if present\n",
    "        if strain != 0:\n",
    "            H0 += strain * (self.Sx * self.Sx - self.Sy * self.Sy)\n",
    "        \n",
    "        # Zeeman term: gamma_e * B * Sz\n",
    "        H0 += self.gamma_e * B_field * self.Sz\n",
    "        \n",
    "        # Expand to full Hilbert space\n",
    "        ops = [H0] + [qeye(2)] * n_nuclear\n",
    "        H = tensor(ops)\n",
    "        \n",
    "        # Add hyperfine interactions for each nuclear spin\n",
    "        for i, (A_parallel, A_perp) in enumerate(A_hyperfine):\n",
    "            # Parallel component: A_parallel * Sz * Iz\n",
    "            ops_parallel = [self.Sz] + [qeye(2)] * n_nuclear\n",
    "            ops_parallel[i + 1] = self.Iz\n",
    "            H += A_parallel * tensor(ops_parallel)\n",
    "            \n",
    "            # Perpendicular components: A_perp * (Sx*Ix + Sy*Iy)\n",
    "            ops_x = [self.Sx] + [qeye(2)] * n_nuclear\n",
    "            ops_x[i + 1] = self.Ix\n",
    "            H += A_perp * tensor(ops_x)\n",
    "            \n",
    "            ops_y = [self.Sy] + [qeye(2)] * n_nuclear\n",
    "            ops_y[i + 1] = self.Iy\n",
    "            H += A_perp * tensor(ops_y)\n",
    "            \n",
    "            # Nuclear Zeeman term\n",
    "            ops_nz = [qeye(3)] + [qeye(2)] * n_nuclear\n",
    "            ops_nz[i + 1] = self.Iz\n",
    "            H += self.gamma_n * B_field * tensor(ops_nz)\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    def odmr_signal(self, freq_range, B_field, nuclear_config, A_hyperfine, \n",
    "                    T1=1e6, T2=1e3, rabi_freq=10.0, pulse_time=1000):\n",
    "        \"\"\"\n",
    "        Simulate ODMR signal with dissipation\n",
    "        \n",
    "        Args:\n",
    "            freq_range: Array of microwave frequencies (MHz)\n",
    "            B_field: Magnetic field (mT)\n",
    "            nuclear_config: Nuclear spin states\n",
    "            A_hyperfine: Hyperfine couplings\n",
    "            T1: Longitudinal relaxation time (ns)\n",
    "            T2: Transverse relaxation time (ns)\n",
    "            rabi_freq: Rabi frequency of MW drive (MHz)\n",
    "            pulse_time: MW pulse duration (ns)\n",
    "        \"\"\"\n",
    "        n_nuclear = len(nuclear_config)\n",
    "        dims = [3] + [2] * n_nuclear\n",
    "        \n",
    "        # Initial state: |ms=0> ⊗ |nuclear_config>\n",
    "        psi0_list = [basis(3, 1)]  # ms=0 state\n",
    "        for config in nuclear_config:\n",
    "            psi0_list.append(basis(2, config))\n",
    "        psi0 = tensor(psi0_list)\n",
    "        \n",
    "        # Build static Hamiltonian\n",
    "        H_static = self.build_hamiltonian(B_field, nuclear_config, A_hyperfine)\n",
    "        \n",
    "        # Measurement operator: population in ms=±1 states\n",
    "        proj_minus1 = basis(3, 0) * basis(3, 0).dag()\n",
    "        proj_plus1 = basis(3, 2) * basis(3, 2).dag()\n",
    "        ops_measure = [proj_minus1 + proj_plus1] + [qeye(2)] * n_nuclear\n",
    "        measure_op = tensor(ops_measure)\n",
    "        \n",
    "        odmr_spectrum = []\n",
    "        \n",
    "        for freq in freq_range:\n",
    "            # Time-dependent Hamiltonian: H = H_static + Omega * cos(2*pi*freq*t) * Sx\n",
    "            # Drive term\n",
    "            ops_drive = [self.Sx] + [qeye(2)] * n_nuclear\n",
    "            H_drive = rabi_freq * tensor(ops_drive)\n",
    "            \n",
    "            # For simplicity, use rotating wave approximation\n",
    "            # Effective Hamiltonian in rotating frame\n",
    "            detuning = freq - (self.D + self.gamma_e * B_field)\n",
    "            ops_det = [self.Sz] + [qeye(2)] * n_nuclear\n",
    "            H_eff = H_static - freq * tensor(ops_det) + H_drive\n",
    "            \n",
    "            # Collapse operators for dissipation\n",
    "            # T1 relaxation\n",
    "            gamma1 = 1.0 / T1\n",
    "            ops_c1a = [basis(3, 1) * basis(3, 0).dag()] + [qeye(2)] * n_nuclear\n",
    "            ops_c1b = [basis(3, 1) * basis(3, 2).dag()] + [qeye(2)] * n_nuclear\n",
    "            c_ops = [\n",
    "                np.sqrt(gamma1) * tensor(ops_c1a),\n",
    "                np.sqrt(gamma1) * tensor(ops_c1b)\n",
    "            ]\n",
    "            \n",
    "            # T2 dephasing (simplified)\n",
    "            gamma2 = 1.0 / T2\n",
    "            ops_deph = [self.Sz] + [qeye(2)] * n_nuclear\n",
    "            c_ops.append(np.sqrt(gamma2) * tensor(ops_deph))\n",
    "            \n",
    "            # Time evolution\n",
    "            times = np.linspace(0, pulse_time, 50)\n",
    "            \n",
    "            try:\n",
    "                result = mesolve(H_eff, psi0, times, c_ops, [measure_op])\n",
    "                \n",
    "                # ODMR signal is population in excited states after pulse\n",
    "                signal = result.expect[0][-1]\n",
    "                odmr_spectrum.append(signal)\n",
    "            except:\n",
    "                # If simulation fails, use approximate value\n",
    "                odmr_spectrum.append(0.5)\n",
    "        \n",
    "        return np.array(odmr_spectrum)\n",
    "    \n",
    "    def generate_sample(self, n_nuclear=3, B_field=None, add_noise=True):\n",
    "        \"\"\"Generate a single ODMR sample with random nuclear configuration\"\"\"\n",
    "        \n",
    "        # Random magnetic field if not specified\n",
    "        if B_field is None:\n",
    "            B_field = np.random.uniform(0.5, 5.0)  # 0.5-5 mT\n",
    "        \n",
    "        # Random nuclear spin configuration\n",
    "        nuclear_config = np.random.randint(0, 2, n_nuclear)\n",
    "        \n",
    "        # Random nuclear positions (in Angstroms relative to NV)\n",
    "        nuclear_positions = []\n",
    "        A_hyperfine = []\n",
    "        \n",
    "        for _ in range(n_nuclear):\n",
    "            # Distance from NV center (1-10 Angstroms)\n",
    "            r = np.random.uniform(1.0, 10.0)\n",
    "            \n",
    "            # Random angle\n",
    "            theta = np.random.uniform(0, np.pi)\n",
    "            phi = np.random.uniform(0, 2 * np.pi)\n",
    "            \n",
    "            pos = np.array([\n",
    "                r * np.sin(theta) * np.cos(phi),\n",
    "                r * np.sin(theta) * np.sin(phi),\n",
    "                r * np.cos(theta)\n",
    "            ])\n",
    "            nuclear_positions.append(pos)\n",
    "            \n",
    "            # Hyperfine coupling (scales as 1/r^3 for dipolar)\n",
    "            A_parallel = 50.0 / (r ** 3) + np.random.normal(0, 1)\n",
    "            A_perp = 25.0 / (r ** 3) + np.random.normal(0, 0.5)\n",
    "            A_hyperfine.append((A_parallel, A_perp))\n",
    "        \n",
    "        # Frequency range around resonance\n",
    "        center_freq = self.D + self.gamma_e * B_field\n",
    "        freq_range = np.linspace(center_freq - 20, center_freq + 20, 50)\n",
    "        \n",
    "        # Random coherence times\n",
    "        T1 = np.random.uniform(1e5, 1e7)  # 100 us to 10 ms\n",
    "        T2 = np.random.uniform(1e2, 1e4)  # 100 ns to 10 us\n",
    "        \n",
    "        # Simulate ODMR\n",
    "        odmr = self.odmr_signal(\n",
    "            freq_range, B_field, nuclear_config, A_hyperfine,\n",
    "            T1=T1, T2=T2\n",
    "        )\n",
    "        \n",
    "        # Add experimental noise\n",
    "        if add_noise:\n",
    "            noise_level = 0.02\n",
    "            odmr += np.random.normal(0, noise_level, len(odmr))\n",
    "        \n",
    "        return {\n",
    "            'nuclear_positions': np.array(nuclear_positions),\n",
    "            'nuclear_config': nuclear_config,\n",
    "            'A_hyperfine': A_hyperfine,\n",
    "            'B_field': B_field,\n",
    "            'freq_range': freq_range,\n",
    "            'odmr_spectrum': odmr,\n",
    "            'T1': T1,\n",
    "            'T2': T2\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a0a6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 2: Graph Neural Network Architecture\n",
    "# ============================================================================\n",
    "\n",
    "class NVGraphDataset(Dataset):\n",
    "    \"\"\"PyTorch Geometric Dataset for NV center graphs\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=1000, n_nuclear=3):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.n_nuclear = n_nuclear\n",
    "        self.simulator = NVCenterSimulator()\n",
    "        self.data_list = []\n",
    "        \n",
    "        print(f\"Generating {num_samples} synthetic ODMR samples...\")\n",
    "        for i in range(num_samples):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"  Generated {i}/{num_samples}\")\n",
    "            sample = self.simulator.generate_sample(n_nuclear=n_nuclear)\n",
    "            graph = self._create_graph(sample)\n",
    "            self.data_list.append(graph)\n",
    "        print(\"Dataset generation complete!\")\n",
    "    \n",
    "    def _create_graph(self, sample):\n",
    "        \"\"\"Convert NV sample to graph representation\"\"\"\n",
    "        nuclear_pos = sample['nuclear_positions']\n",
    "        n_nuclear = len(nuclear_pos)\n",
    "        \n",
    "        # Node features\n",
    "        # NV center node: [0, 0, 0, B_field, 1] (position + field + type)\n",
    "        nv_node = torch.tensor([[0., 0., 0., sample['B_field'], 1.0]])\n",
    "        \n",
    "        # Nuclear nodes: [x, y, z, spin_state, 0] (position + state + type)\n",
    "        nuclear_nodes = torch.cat([\n",
    "            torch.tensor(nuclear_pos, dtype=torch.float32),\n",
    "            torch.tensor(sample['nuclear_config'], dtype=torch.float32).unsqueeze(1),\n",
    "            torch.zeros(n_nuclear, 1)\n",
    "        ], dim=1)\n",
    "        \n",
    "        x = torch.cat([nv_node, nuclear_nodes], dim=0)\n",
    "        \n",
    "        # Edges: NV to all nuclear spins (bidirectional)\n",
    "        edges = []\n",
    "        edge_features = []\n",
    "        \n",
    "        for i in range(n_nuclear):\n",
    "            # NV to nuclear\n",
    "            edges.append([0, i + 1])\n",
    "            \n",
    "            # Nuclear to NV\n",
    "            edges.append([i + 1, 0])\n",
    "            \n",
    "            # Edge features: [distance, A_parallel, A_perp]\n",
    "            distance = np.linalg.norm(nuclear_pos[i])\n",
    "            A_par, A_perp = sample['A_hyperfine'][i]\n",
    "            edge_feat = [distance, A_par, A_perp]\n",
    "            edge_features.extend([edge_feat, edge_feat])\n",
    "        \n",
    "        # Nuclear-nuclear edges (if close enough)\n",
    "        for i in range(n_nuclear):\n",
    "            for j in range(i + 1, n_nuclear):\n",
    "                dist = np.linalg.norm(nuclear_pos[i] - nuclear_pos[j])\n",
    "                if dist < 5.0:  # Angstroms\n",
    "                    edges.append([i + 1, j + 1])\n",
    "                    edges.append([j + 1, i + 1])\n",
    "                    \n",
    "                    # Dipolar coupling ~ 1/r^3\n",
    "                    coupling = 10.0 / (dist ** 3)\n",
    "                    edge_feat = [dist, coupling, 0.0]\n",
    "                    edge_features.extend([edge_feat, edge_feat])\n",
    "        \n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t()\n",
    "        edge_attr = torch.tensor(edge_features, dtype=torch.float32)\n",
    "        \n",
    "        # Target: ODMR spectrum\n",
    "        y = torch.tensor(sample['odmr_spectrum'], dtype=torch.float32)\n",
    "        \n",
    "        # Additional info\n",
    "        freq_range = torch.tensor(sample['freq_range'], dtype=torch.float32)\n",
    "        coherence = torch.tensor([sample['T1'], sample['T2']], dtype=torch.float32)\n",
    "        \n",
    "        return Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=y,\n",
    "            freq_range=freq_range,\n",
    "            coherence=coherence\n",
    "        )\n",
    "    \n",
    "    def len(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return self.data_list[idx]\n",
    "\n",
    "\n",
    "class NVMessagePassing(MessagePassing):\n",
    "    \"\"\"Custom message passing for NV-nuclear spin interactions\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        \n",
    "        self.message_mlp = nn.Sequential(\n",
    "            nn.Linear(2 * in_channels + 3, out_channels),  # +3 for edge features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "            nn.LayerNorm(out_channels)\n",
    "        )\n",
    "        \n",
    "        self.update_mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels + out_channels, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "    \n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        msg = torch.cat([x_i, x_j, edge_attr], dim=-1)\n",
    "        return self.message_mlp(msg)\n",
    "    \n",
    "    def update(self, aggr_out, x):\n",
    "        return self.update_mlp(torch.cat([x, aggr_out], dim=-1))\n",
    "\n",
    "\n",
    "class NVGNN(nn.Module):\n",
    "    \"\"\"Graph Neural Network for ODMR spectrum prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, node_features=5, edge_features=3, hidden_dim=128, \n",
    "                 num_layers=4, spectrum_length=50):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(node_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(edge_features, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList([\n",
    "            NVMessagePassing(hidden_dim, hidden_dim)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Attention mechanism for aggregation\n",
    "        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)\n",
    "        \n",
    "        # Spectrum prediction head\n",
    "        self.spectrum_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, spectrum_length)\n",
    "        )\n",
    "        \n",
    "        # Coherence time prediction head\n",
    "        self.coherence_head = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 2)  # T1, T2\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = self.node_encoder(data.x)\n",
    "        edge_attr = data.edge_attr\n",
    "        \n",
    "        # Message passing\n",
    "        for conv in self.conv_layers:\n",
    "            x_new = conv(x, data.edge_index, edge_attr)\n",
    "            x = x + x_new  # Residual connection\n",
    "        \n",
    "        # Extract NV center embedding (first node)\n",
    "        batch_size = data.batch.max().item() + 1\n",
    "        nv_embeddings = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask = data.batch == i\n",
    "            nv_idx = torch.where(mask)[0][0]  # First node in each graph\n",
    "            nv_embeddings.append(x[nv_idx])\n",
    "        \n",
    "        nv_embedding = torch.stack(nv_embeddings)\n",
    "        \n",
    "        # Predict ODMR spectrum\n",
    "        spectrum = self.spectrum_head(nv_embedding)\n",
    "        \n",
    "        # Predict coherence times\n",
    "        coherence = self.coherence_head(nv_embedding)\n",
    "        coherence = torch.exp(coherence)  # Ensure positive\n",
    "        \n",
    "        return {\n",
    "            'spectrum': spectrum,\n",
    "            'coherence': coherence\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c158304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 3: Training and Evaluation\n",
    "# ============================================================================\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=50, device='cpu'):\n",
    "    \"\"\"Train the NV GNN model\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = model(batch)\n",
    "            \n",
    "            # Loss: MSE for spectrum + MSE for coherence\n",
    "            spectrum_loss = nn.functional.mse_loss(predictions['spectrum'], batch.y)\n",
    "            coherence_loss = nn.functional.mse_loss(\n",
    "                torch.log(predictions['coherence']), \n",
    "                torch.log(batch.coherence)\n",
    "            )\n",
    "            \n",
    "            loss = spectrum_loss + 0.1 * coherence_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                predictions = model(batch)\n",
    "                \n",
    "                spectrum_loss = nn.functional.mse_loss(predictions['spectrum'], batch.y)\n",
    "                coherence_loss = nn.functional.mse_loss(\n",
    "                    torch.log(predictions['coherence']), \n",
    "                    torch.log(batch.coherence)\n",
    "                )\n",
    "                loss = spectrum_loss + 0.1 * coherence_loss\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "        \n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        \n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        \n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_nv_gnn.pt')\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"Epoch {epoch:3d}: Train Loss = {avg_train_loss:.6f}, \"\n",
    "                  f\"Val Loss = {avg_val_loss:.6f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "def visualize_predictions(model, dataset, device='cpu', num_samples=3):\n",
    "    \"\"\"Visualize ODMR predictions vs ground truth\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4 * num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            idx = np.random.randint(len(dataset))\n",
    "            data = dataset[idx].to(device)\n",
    "            \n",
    "            # Add batch dimension\n",
    "            data.batch = torch.zeros(data.x.size(0), dtype=torch.long)\n",
    "            \n",
    "            predictions = model(data)\n",
    "            \n",
    "            # ODMR spectrum\n",
    "            ax = axes[i, 0] if num_samples > 1 else axes[0]\n",
    "            freq = data.freq_range.cpu().numpy()\n",
    "            true_spectrum = data.y.cpu().numpy()\n",
    "            pred_spectrum = predictions['spectrum'][0].cpu().numpy()\n",
    "            \n",
    "            ax.plot(freq, true_spectrum, 'b-', label='True', linewidth=2)\n",
    "            ax.plot(freq, pred_spectrum, 'r--', label='Predicted', linewidth=2)\n",
    "            ax.set_xlabel('Frequency (MHz)', fontsize=12)\n",
    "            ax.set_ylabel('ODMR Signal', fontsize=12)\n",
    "            ax.set_title(f'Sample {idx}: ODMR Spectrum', fontsize=14)\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Coherence times comparison\n",
    "            ax = axes[i, 1] if num_samples > 1 else axes[1]\n",
    "            true_coh = data.coherence.cpu().numpy()\n",
    "            pred_coh = predictions['coherence'][0].cpu().numpy()\n",
    "            \n",
    "            x = np.arange(2)\n",
    "            width = 0.35\n",
    "            ax.bar(x - width/2, true_coh / 1e3, width, label='True', alpha=0.7)\n",
    "            ax.bar(x + width/2, pred_coh / 1e3, width, label='Predicted', alpha=0.7)\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(['T₁', 'T₂'])\n",
    "            ax.set_ylabel('Time (μs)', fontsize=12)\n",
    "            ax.set_title(f'Sample {idx}: Coherence Times', fontsize=14)\n",
    "            ax.legend()\n",
    "            ax.set_yscale('log')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da94939d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "============================================================\n",
      "GENERATING SYNTHETIC ODMR DATA\n",
      "============================================================\n",
      "Generating 500 synthetic ODMR samples...\n",
      "  Generated 0/500\n",
      "  Generated 100/500\n",
      "  Generated 200/500\n",
      "  Generated 300/500\n",
      "  Generated 400/500\n",
      "Dataset generation complete!\n",
      "Generating 100 synthetic ODMR samples...\n",
      "  Generated 0/100\n",
      "Dataset generation complete!\n",
      "\n",
      "============================================================\n",
      "BUILDING GRAPH NEURAL NETWORK\n",
      "============================================================\n",
      "Model parameters: 497,396\n",
      "\n",
      "============================================================\n",
      "TRAINING MODEL\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (800) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTRAINING MODEL\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Visualize results\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, epochs, device)\u001b[39m\n\u001b[32m     26\u001b[39m predictions = model(batch)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Loss: MSE for spectrum + MSE for coherence\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m spectrum_loss = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspectrum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m coherence_loss = nn.functional.mse_loss(\n\u001b[32m     31\u001b[39m     torch.log(predictions[\u001b[33m'\u001b[39m\u001b[33mcoherence\u001b[39m\u001b[33m'\u001b[39m]), \n\u001b[32m     32\u001b[39m     torch.log(batch.coherence)\n\u001b[32m     33\u001b[39m )\n\u001b[32m     35\u001b[39m loss = spectrum_loss + \u001b[32m0.1\u001b[39m * coherence_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/deeplearning/.venv/lib/python3.11/site-packages/torch/nn/functional.py:3338\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction)\u001b[39m\n\u001b[32m   3335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3336\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3338\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3339\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/deeplearning/.venv/lib/python3.11/site-packages/torch/functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (50) must match the size of tensor b (800) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# PART 4: Main Execution\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Check for GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Generate dataset\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING SYNTHETIC ODMR DATA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    train_dataset = NVGraphDataset(num_samples=500, n_nuclear=3)\n",
    "    val_dataset = NVGraphDataset(num_samples=100, n_nuclear=3)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Create model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BUILDING GRAPH NEURAL NETWORK\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    model = NVGNN(\n",
    "        node_features=5,\n",
    "        edge_features=3,\n",
    "        hidden_dim=128,\n",
    "        num_layers=4,\n",
    "        spectrum_length=50\n",
    "    )\n",
    "    \n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # Train model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    history = train_model(\n",
    "        model, train_loader, val_loader,\n",
    "        epochs=30, device=device\n",
    "    )\n",
    "    \n",
    "    # Visualize results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"GENERATING PREDICTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load('best_nv_gnn.pt'))\n",
    "    model = model.to(device)\n",
    "    \n",
    "    fig = visualize_predictions(model, val_dataset, device=device, num_samples=3)\n",
    "    plt.savefig('nv_odmr_predictions.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"\\nPredictions saved to 'nv_odmr_predictions.png'\")\n",
    "    \n",
    "    # Training history\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "    ax.plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax.set_xlabel('Epoch', fontsize=12)\n",
    "    ax.set_ylabel('Loss', fontsize=12)\n",
    "    ax.set_title('Training History', fontsize=14)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Training history saved to 'training_history.png'\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Best validation loss: {min(history['val_loss']):.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
